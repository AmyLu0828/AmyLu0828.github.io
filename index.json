[{"content":"My first learning experience with a full stack project with AI agents is with this project https://github.com/coleam00/Archon.\nThis project is aimed at building an agent with Pydantic AI and Langraph that builds other agents.\nThis is the hands on best project for beginners who just had some encounterance with Agentic workflows, but has only built small-scaled demos and is wondering how these workflows can be turned into actual products/applications.\nThe best part of this project to me is that it includes 6 iterations. This gradual process of adding features and optimizations make it easier for me to follow - if you were to throw at me the final version at the very beginning I would not have understand. So, let’s get started.\nVersion 1: Simple Pydantic Agent Version 1 is a simple Pydantic AI Agent with RAG. The major point here is the RAG, as, to let your agent be able to generate code with Pydantic_ai, it must know the syntax of Pydantic_ai and perhaps some examples in building with that framework. This is provided with RAG, by retrieving crawled pydantic_ai documentation from a database.\nSo, the workflow is as such:\nCrawl pydantic_ai docs into Supabase Get urls from pydantic ai sitemap For each url… Fetch the content in the webpage Process and store the content Split the text into reasonable chunks Process the chunks - extracting title and summary, generating embeddings Insert into the database Streamlit Frontend Collect message history With the user’s input Start streaming with pydantic_ai_coder and collect the result Output the result in real time Add the result to the message history Pydantic AI Coder Tools: retrieve relevant documentation - find the relevant documentation by embedding the user’s query list documentation pages - list all the available pages get page content - get the content from an url Version 2: Orchestration with Langgraph Version 2 optimized on version 1 by breaking up the agentic task into a workflow. Karpathy mentioned in https://www.youtube.com/watch?v=LCEmiRjPEtQ\u0026amp;t=1373 that currently, the best agents are those that support an effective AI-Human coorperation. AI excels at generation but is not yet ready to take full control and should always be supervised by humans. Therefore, the best approach is to “keep AI on a leash” by incorporating human verification throughout the process.\nVersion 1 allowed too much autonomy to the AI—it decided entirely what to do first, which tools to use, and so on, without any guidance or human oversight. However, for AI coding tasks, certain steps are clearly necessary and should be made mandatory. Additionally, human supervision must be integrated into the workflow.\nThis leads to two possibilities for optimization:\nImplement restrictions on AI by using built-in workflows that break down tasks, reducing its autonomy and guiding its actions. Incorporate human-in-the-loop supervision so that users can monitor the workflow and make decisions at critical points. Thus, version 2 built, upon version 1, a workflow with langgraph…\nScope Reasoner: has a view of the use query and all the documents collected about Pydantic AI, and with these, it generates a scope including the architecture, core compoennts, external dependencies, and lists the urls it finds useful for the coder agent to use.\nGet Next User Message: uses langgraph’s human in the loop feature interrupt() to catch the user input from the frontend, and then resume the thread.\nVersion 3: Adding MCP Previously, I did not fully understand the purpose of MCP. Like the question in this post, https://www.reddit.com/r/ClaudeAI/comments/1h0w1z6/model_context_protocol_vs_function_calling_whats/, I didn’t really see the difference between MCP and Function Calling. I’ve also heard that MCP does not have much use for small personal projects, so I was spectulative in what it can do.\nHowever, I think v3 got me a lot closer to understanding what MCP is.\nSuppose I want to deploy this Pydantic AI generator to an IDE like Cursor, allowing me to use the generator within the Cursor chat and run the generated code directly. Previously, implementing this integration would have been difficult. However, since Cursor supports the Model Context Protocol (MCP), the process is now much simpler. All I need to do is build an MCP server for my agent, expose the agent’s calling function, and Cursor can then directly communicate with my agent to request and retrieve results.\nThus, while the Streamlit UI exposes my agent directly to users through a chat interface, the MCP exposes my agent to AI IDEs.\nVersion 4: Complete Streamlit UI With all the features listed above, v4 constructs a complete frontend with the following tabs: introduction, enviornment, chat, database, documentation, agent service, mcp.\nOne major concept that is added:\nReal-Time Progress Tracking for Long-Running Crawling Tasks When building a web crawler or any long-running asynchronous task, it\u0026rsquo;s crucial to provide real-time feedback to users. Since crawling can take a significant amount of time, users naturally want to see the current progress instead of waiting blindly for completion.\nTo address this, we use a Progress Tracker that acts as a bridge between the backend crawling process and the frontend user interface (UI). The main idea is:\nThe UI passes a callback function to the crawling thread. The crawling thread creates a Progress Tracker instance. The tracker exposes methods like .log(), .start(), .complete(), and .get_status(). Each time one of these methods is called during crawling, the tracker uses the callback to send updated status information back to the UI. The frontend stores this status and updates the display in real time, showing progress bars, logs, counts, and other useful metrics. #documentation_tab.py def update_progress(status): st.session_state.crawl_status = status st.session_state.crawl_tracker = start_crawl_with_request(update_progress) st.session_state.crawl_status = st.session_state.crawl_tracker.get_status() #crawl_pydantic_ai_docs.py class CrawlProgressTracker: def __init__(self, progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None): #Callable[[input_type], output_type] self.progress_callback = progress_callback self.urls_found = 0 self.urls_processed = 0 self.urls_failed = 0 self.urls_succeeded = 0 self.chunks_stored = 0 self.logs = [] self.is_running = False self.start_time = None self.end_time = None def log(self, message: str): current_time = datetime.now().strftime(\u0026#34;%H:%M:%S\u0026#34;) self.logs.append(f\u0026#34;[{current_time}] {message}\u0026#34;) print(message) #call progress_callback if provided if self.progress_callback: self.progress_callback(self.get_status()) def start(self): ... if self.progress_callback: self.progress_callback(self.get_status()) def complete(self): ... def get_status(self) -\u0026gt; Dict[str, Any]: return { \u0026#34;urls_found\u0026#34;: self.urls_found, \u0026#34;urls_processed\u0026#34;: self.urls_processed, \u0026#34;urls_succeeded\u0026#34;: self.urls_succeeded, \u0026#34;urls_failed\u0026#34;: self.urls_failed, \u0026#34;chunks_stored\u0026#34;: self.chunks_stored, \u0026#34;progress_percentage\u0026#34;: self.urls_processed / self.urls_found * 100 if self.urls_found \u0026gt; 0 else 0, \u0026#34;logs\u0026#34;: self.logs, \u0026#34;start_time\u0026#34;: self.start_time, \u0026#34;end_time\u0026#34;: self.end_time } @property #used to define a method as a \u0026#34;getter\u0026#34; for a class attribute, allowing you to access it like a property (without parentheses) def is_completed(self) -\u0026gt; bool: return not self.is_running and self.end_time is not None @property def is_successful(self) -\u0026gt; bool: return self.is_completed and self.urls_failed == 0 and self.urls_succeeded \u0026gt; 0 ... def start_crawl_with_requests(progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None): tracker = CrawlProgressTracker(progress_callback) def run_crawl(): try: asyncio.run(main_with_requests(tracker)) except Exception as e: print(f\u0026#34;Error starting crawling: {str(e)}\u0026#34;) tracker.log(f\u0026#34;Error starting crawling: {str(e)}\u0026#34;) tracker.complete() thread = threading.Thread(target=run_crawl) thread.daemon = True #allows the thread to exit when the main program exits thread.start() Version 5: Optimizing Archon: Smarter Crawling and Streamlined Agent Coordination While the previous setup looked solid in theory, when I actually ran Archon, its performance was underwhelming. The code it generated for building Pydantic AI agents didn’t really seem like it had read the documentation we gave it. For example, check out this snippet — it defines a Pydantic AI agent in a way that’s completely different from the docs, and it doesn’t even import pydantic_ai.\nThat made me suspect something was off with the RAG part. Since RAG is supposed to be the heart of this project — the part that helps the agent actually use the docs — it seemed like the agent wasn’t really accessing or understanding the documentation properly.\nProblem 1: Missing Important Docs Here’s a quick refresher on the tools the coder agent has:\nretrieve_relevant_documentation — looks up docs based on how similar they are to the user’s query. list_documentation_pages — lists all the documentation pages available. get_page_content — fetches the content of a specific page. retrieve_relevant_documentation is the one used most often. But the problem is, it doesn’t always bring back all the important docs. For example, if a user says:\nUser: Build me an Weather Agent that can tell me the weather of a certain place at any time. The system, with embeddings, might pull up docs about “Weather Agent” or “weather at a place,” but it could easily miss key pages like /agent, /messages, or /tools — which are crucial for building the agent correctly.\nHowever, remember that the Scope Reasoner already knows which docs are important and picks out the URLs it thinks are needed. The problem was that these URLs weren’t always actually crawled and passed to the coder agent.\nTo fix this, I changed how the Scope Reasoner talks to the coder agent:\nInstead of just sending a string, it now sends a JSON object like this: {\u0026#34;scope\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;selected_urls\u0026#34;: [...]} And then I made sure the coder agent has to crawl all those URLs before it starts coding. Here’s a snippet from the system prompt that enforces this: @ai_coder.system_prompt def add_info(ctx: RunContext[AIDeps]) -\u0026gt; str: print(ctx.deps.selected_urls) return f\u0026#34;\u0026#34;\u0026#34; \\n\\n !!!IMPORTANT!!! YOU MUST BUILD YOUR AGENT IN THE {ctx.deps.framework} FRAMEWORK. !!!IMPORTANT!!! YOU MUST GET THE CONTENT FROM ALL THESE URLS {ctx.deps.selected_urls}. [WORKFLOW] 1. Research - 1.1: get the contents from all the urls listed above with get_page_content tool - 1.2: RAG search for relevant documentation based on the query - 1.3: If you feel like you need anything else, use list_documentation_pages tool to get a list of all the documentation pages for this framework 2. Implementation - 2.1 Provide complete, working code following framework best practices - 2.2 YOU MUST SPLIT UP THE FILES, do not have one single file with all the code. Learn how to split up your code with the documentation. - 2.2 Include necessary comments and documentation [FRAMEWORK ADAPTATION] Your code structure and approach should adapt based on the framework: \\n\\nAdditional Instructions from the reasoner LLM: {ctx.deps.scope} \u0026#34;\u0026#34;\u0026#34; This way, the agent has to include all the important documentation.\nProblem 2: Too Much Noise in the Crawled Content Once I fixed that, another problem popped up. The content the agent crawled was full of junk — things like navigation menus, line numbers in code blocks, page margins, and other stuff that doesn\u0026rsquo;t help at all.\nIf you take the first 20,000 characters of that content, more than half of it is just noise. That wastes tokens and makes it harder for the agent to focus on the useful parts.\nSo, to really improve Archon, I realized we need to make the crawling smarter — extracting only the meaningful documentation and ignoring all the clutter. ","permalink":"https://amylu0828.github.io/posts/archon-post/","summary":"\u003cp\u003eMy first learning experience with a full stack project with AI agents is with this project  \u003ca href=\"https://github.com/coleam00/Archon\"\u003ehttps://github.com/coleam00/Archon\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThis project is aimed at building an agent with Pydantic AI and Langraph that builds other agents.\u003c/p\u003e\n\u003cp\u003eThis is the hands on best project for beginners who just had some encounterance with Agentic workflows, but has only built small-scaled demos and is wondering how these workflows can be turned into actual products/applications.\u003c/p\u003e\n\u003cp\u003eThe best part of this project to me is that it includes 6 iterations. This gradual process of adding features and optimizations make it easier for me to follow - if you were to throw at me the final version at the very beginning I would not have understand. So, let’s get started.\u003c/p\u003e","title":"Archon"},{"content":"Introductory Resources Anthropic has this great introduction to AI Agents - from definition to basic patterns. This is the first post I read, and it gave me a general idea of what AI Agents are, and very importantly, the difference between AI Agents and workflows.\nBuilding Effective Agents\nNow, to actually start learning, I find this blog by Galileo a good guideline for the different stages (and complexities) in building AI Agents, and my learning is also pretty much down this path.\nA Field Guide to AI Agents\nStep 1: Workflows YouTube Tutorial\nI started with this YouTube tutorial (as I saw other Reddit posts recommending to start with this).\nWhy this is a good project at this step: It starts from the very basics of API calling, function calling, structured output and then explores different workflows (from Anthropic\u0026rsquo;s article) It uses pure Python and does not use any frameworks Uses an easy example of [your example here] What I learned: A workflow is essentially breaking down a problem into several steps, with each step taken care of by an LLM call and then chaining these calls together. What\u0026rsquo;s crucial here is to specify the connections between different calls, and this is where structured output comes in. Logging information is very helpful - it shows you in time which step the AI Agent is at, and is helpful for debugging Note: Not all AI models support structured output. I started with this tutorial using Groq - as it\u0026rsquo;s free and pretty good - but it does not support structured output, so I eventually switched to OpenAI. What I wonder: What is the actual difference between workflow and agents?\nStep 2 - Route 1: Basic Agents (ReAct) Obviously, Step 1 is not good enough, and although it is briefly introduced in Anthropic\u0026rsquo;s article, it makes me wonder: what is the actual difference between a workflow and an agent. I think I found the answer to this question through this project:\nText2SQL Project (Chinese)\nIt\u0026rsquo;s a text2sql project with simple coding and agent structure. It\u0026rsquo;s in Chinese though, but I\u0026rsquo;m sure it is possible to find similar tutorials in English.\nWhy this is a good project at this step: It\u0026rsquo;s implemented in two ways - a basic way (workflow), and an optimized way (agent + other optimizations). This makes the difference between a workflow and agent very clear. A great introduction to the ReAct (reasoning+action) framework All data are preprocessed - there are no tedious data cleaning required It uses a bit of Langchain, but I understood the code without any previous acquaintance with Langchain What I learned: The actual difference between workflows and agents:\nWorkflow: A manually designed structured sequence of steps, calling the LLM at each step Agent: An autonomous entity that can interpret inputs, generate and examine its own outputs, make decisions, and invoke actions dynamically Example:\nWorkflow:\nExtract schema from data Generate SQL (with user query and schema) Run SQL\n(The steps and connections between steps are predefined by us) Agent:\nExtract schema from data Generate SQL and wrap into a json request Decides whether to use tool run_sql_query Tool use If execution fails, goes back to (2); if it worked continues to (5) Decides whether to use tool file_saver (print the retrieved data into a file)\n(Steps 2-5 are all entirely controlled by the LLM) The ReAct framework - Thought (Reasoning) + Action. Seeing the output of the agent in the end makes it very clear how this framework is useful.\nSide knowledge #1: Basics of SQL, SQLite, Schema - I previously had no knowledge of any of these, but now have a vague sense of how these things work and how to interact with databases.\nSide knowledge #2: The project also optimizes schema with a more effective m_schema presented by Alibaba\u0026rsquo;s Xi-yan. Although I didn\u0026rsquo;t go into the details, it is interesting to see how the optimization works.\nWhat I wonder: Now, I\u0026rsquo;m interested in Langchain. The ReAct framework (which is the reason that this process is automated) is coded in Langchain.\n","permalink":"https://amylu0828.github.io/posts/mypost/","summary":"\u003ch2 id=\"introductory-resources\"\u003eIntroductory Resources\u003c/h2\u003e\n\u003cp\u003eAnthropic has this great introduction to \u003cstrong\u003eAI Agents\u003c/strong\u003e - from definition to basic patterns. This is the first post I read, and it gave me a general idea of what AI Agents are, and very importantly, the difference between AI Agents and workflows.\u003cbr\u003e\n\u003ca href=\"https://www.anthropic.com/engineering/building-effective-agents\"\u003eBuilding Effective Agents\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eNow, to actually start learning, I find this blog by Galileo a good guideline for the different stages (and complexities) in building AI Agents, and my learning is also pretty much down this path.\u003cbr\u003e\n\u003ca href=\"https://galileo.ai/blog/a-field-guide-to-ai-agents?utm_source=reddit\u0026amp;utm_content=ai_agents\"\u003eA Field Guide to AI Agents\u003c/a\u003e\u003c/p\u003e","title":"Getting Started with AI Agents"}]